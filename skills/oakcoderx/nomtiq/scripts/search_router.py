#!/usr/bin/env python3
"""
Nomtiq å°é¥­ç¥¨ - æ™ºèƒ½è·¯ç”±æœç´¢
è‡ªåŠ¨åˆ¤æ–­ç”¨æˆ· localeï¼Œåˆ‡æ¢å¯¹åº”æ•°æ®æºï¼š
  - ä¸­å›½å¢ƒå†… â†’ å¤§ä¼—ç‚¹è¯„ + å°çº¢ä¹¦
  - æµ·å¤–åäºº â†’ Google Places + Yelp + å°çº¢ä¹¦
  - æµ·å¤–ç”¨æˆ· â†’ Google Places + Yelp + Reddit

ç”¨æ³•:
  python3 search_all.py "ä¸‰é‡Œå±¯ åˆ›æ„èœ"
  python3 search_all.py "ramen Manhattan" --city "New York"
  python3 search_all.py "dim sum Flushing" --city "New York" --locale overseas-chinese
"""

import sys
import json
import argparse
import re
import os
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent))
from search import search_dianping
from search_xhs import search_xiaohongshu
from search_global import search_all_global
from search_maps import search_maps, search_serper_maps, cross_verify_social

DATA_DIR = Path(__file__).parent.parent / 'data'
PROFILE_PATH = DATA_DIR / 'taste-profile.json'


# â”€â”€ Locale è‡ªåŠ¨æ¨æ–­ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CHINA_SIGNALS = [
    # ä¸­æ–‡åœ°å
    'åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æˆéƒ½', 'æ­å·', 'æ­¦æ±‰', 'è¥¿å®‰', 'å—äº¬', 'é‡åº†',
    'ä¸‰é‡Œå±¯', 'å›½è´¸', 'æœ›äº¬', 'æœé˜³', 'æµ·æ·€', 'ä¸œåŸ', 'è¥¿åŸ',
    # ä¸­æ–‡èœç³»
    'å·èœ', 'ç²¤èœ', 'æ¹˜èœ', 'é—½èœ', 'è‹èœ', 'æµ™èœ', 'é²èœ', 'å¾½èœ',
    'ç«é”…', 'ä¸²ä¸²', 'çƒ¤é¸­', 'å°ç¬¼åŒ…', 'å¤§ä¼—ç‚¹è¯„',
    # è´§å¸
    'äººå‡', 'Â¥',
]

OVERSEAS_CHINESE_SIGNALS = [
    # æµ·å¤–åäººèšé›†åœ°
    'flushing', 'chinatown', 'monterey park', 'richmond', 'markham',
    'chatswood', 'box hill', 'cabramatta',
    # è‹±æ–‡ä½†æœä¸­é¤
    'dim sum', 'hot pot', 'xiaolongbao', 'malatang', 'chuan', 'cantonese',
    # å°çº¢ä¹¦ç›¸å…³
    'å°çº¢ä¹¦', 'æ¢åº—', 'æµ·å¤–',
]

OVERSEAS_SIGNALS = [
    # è‹±æ–‡åŸå¸‚
    'new york', 'manhattan', 'brooklyn', 'los angeles', 'san francisco',
    'london', 'paris', 'tokyo', 'osaka', 'seoul', 'singapore', 'sydney',
    'toronto', 'vancouver', 'melbourne', 'bangkok',
    # è‹±æ–‡èœç³»
    'italian', 'french', 'japanese', 'korean', 'thai', 'mexican', 'indian',
    'sushi', 'ramen', 'pizza', 'burger', 'steak',
    # è´§å¸
    '$', 'â‚¬', 'Â£', 'Â¥ jpy',
]


def detect_locale(query: str, city: str = '', profile: dict = None) -> str:
    """
    è‡ªåŠ¨æ¨æ–­ç”¨æˆ· locale
    è¿”å›: 'china' | 'overseas-chinese' | 'overseas'
    """
    text = f"{query} {city}".lower()

    # 1. å…ˆçœ‹ taste-profile é‡Œæœ‰æ²¡æœ‰è®°å½•çš„ locale
    if profile and profile.get('user', {}).get('locale'):
        return profile['user']['locale']

    # 2. çœ‹ profile é‡Œçš„åŸå¸‚
    if profile:
        user_city = profile.get('user', {}).get('city', '')
        if user_city and any(s in user_city for s in ['åŒ—äº¬', 'ä¸Šæµ·', 'å¹¿å·', 'æ·±åœ³', 'æˆéƒ½']):
            return 'china'

    # 3. ä» query æ¨æ–­
    china_score = sum(1 for s in CHINA_SIGNALS if s.lower() in text)
    oc_score = sum(1 for s in OVERSEAS_CHINESE_SIGNALS if s.lower() in text)
    overseas_score = sum(1 for s in OVERSEAS_SIGNALS if s.lower() in text)

    # ä¸­æ–‡å­—ç¬¦æ¯”ä¾‹
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
    if chinese_chars > 3:
        china_score += 2

    if china_score >= 2:
        return 'china'
    if oc_score >= 1 or (chinese_chars > 0 and overseas_score >= 1):
        return 'overseas-chinese'
    if overseas_score >= 1:
        return 'overseas'

    # é»˜è®¤ï¼šæœ‰ä¸­æ–‡å°±æ˜¯ä¸­å›½
    return 'china' if chinese_chars > 0 else 'overseas'


# â”€â”€ åŒ¹é…åº¦è®¡ç®— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def match_score(restaurant: dict, preferences: dict, locale: str) -> float:
    if not preferences:
        return 50

    score = 50
    liked_tags = set(preferences.get('liked_tags', []))
    disliked_tags = set(preferences.get('disliked_tags', []))
    price_range = preferences.get('price_range', [])

    # ä¸­å›½ç‰ˆï¼šç”¨ categories/tags
    if locale == 'china':
        restaurant_tags = set(restaurant.get('categories', []) + restaurant.get('tags', []))
    else:
        # æµ·å¤–ç‰ˆï¼šç”¨ cuisines
        restaurant_tags = set(restaurant.get('cuisines', []))

    matched = liked_tags & restaurant_tags
    score += len(matched) * 5
    anti = disliked_tags & restaurant_tags
    score -= len(anti) * 10

    # ä»·æ ¼åŒ¹é…
    price = restaurant.get('avg_price') or restaurant.get('price_level')
    if price and price_range and len(price_range) == 2:
        low, high = price_range
        if locale != 'china' and restaurant.get('price_level'):
            # æµ·å¤–ï¼šprice_level 1-4 æ˜ å°„åˆ°ä»·æ ¼æ¡£
            pass
        else:
            margin = (high - low) * 0.3
            if low - margin <= price <= high + margin:
                score += 5

    # äº¤å‰éªŒè¯åŠ åˆ†
    if restaurant.get('cross_verified'):
        score += 10
    if restaurant.get('reddit_mentioned'):
        score += 8  # Reddit æœ¬åœ°å£ç¢‘
    if restaurant.get('xhs_verified'):
        score += 6  # å°çº¢ä¹¦åäººéªŒè¯

    # å°çº¢ä¹¦æƒ…æ„Ÿ
    sentiment = restaurant.get('xhs_sentiment') or restaurant.get('reddit_sentiment')
    if sentiment == 'positive':
        score += 5
    elif sentiment == 'negative':
        score -= 8

    return min(max(score, 0), 100)


def select_2plus1(merged: list) -> tuple:
    precise = [r for r in merged if r.get('match_score', 50) >= 70 and r.get('cross_verified')]
    explorer = [r for r in merged if 60 <= r.get('match_score', 50) <= 75
                and (r.get('reddit_mentioned') or r.get('xhs_sentiment') == 'positive')]

    if len(precise) < 2:
        precise = sorted(merged, key=lambda x: x.get('match_score', 50), reverse=True)[:2]
    if not explorer:
        explorer = [r for r in merged if r.get('match_score', 50) >= 65][:1]

    return precise[:2], explorer[:1]


def load_profile() -> dict:
    if PROFILE_PATH.exists():
        with open(PROFILE_PATH, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def main():
    parser = argparse.ArgumentParser(description='Nomtiq å°é¥­ç¥¨ - æ™ºèƒ½è·¯ç”±æœç´¢')
    parser.add_argument('query', help='æœç´¢å…³é”®è¯ï¼ˆä¸­è‹±æ–‡å‡å¯ï¼‰')
    parser.add_argument('--city', default='', help='åŸå¸‚')
    parser.add_argument('--max', type=int, default=40, help='æœ€å¤§ç»“æœæ•°')
    parser.add_argument('--locale', choices=['china', 'overseas-chinese', 'overseas', 'auto'],
                        default='auto', help='ç”¨æˆ· localeï¼ˆé»˜è®¤è‡ªåŠ¨æ¨æ–­ï¼‰')
    parser.add_argument('--mode', choices=['normal', '2plus1'], default='2plus1')
    parser.add_argument('--scene', default='', help='åœºæ™¯ï¼šbirthday/ex/business/date/friends/solo')
    parser.add_argument('--people', type=int, default=2, help='äººæ•°')
    parser.add_argument('--json', action='store_true', help='JSON è¾“å‡º')
    args = parser.parse_args()

    profile = load_profile()
    preferences = profile.get('preferences', {})

    # åœºæ™¯ â†’ æœç´¢è¯è°ƒæ•´
    SCENE_QUERY_MAP = {
        'birthday':  'ç²¾è‡´é¤å… ç‰¹è‰²',
        'ex':        'ç‰¹è‰²å°é¦† æœ‰è°ƒæ€§',
        'business':  'å•†åŠ¡é¤å… åŒ…é—´',
        'date':      'ç²¾è‡´ æœ‰è°ƒæ€§ å®‰é™',
        'friends':   'èšé¤ ç‰¹è‰²',
        'solo':      'å°é¦† ä¸€äººé£Ÿ',
    }
    SCENE_TONE = {
        'birthday': 'ç¯å¢ƒæœ¬èº«å°±æ˜¯ç¤¼ç‰©',
        'ex':       'å¥½å¥½åƒé¡¿é¥­ï¼Œä¸ç”¨å¤ªå¤šä»ªå¼æ„Ÿ',
        'business': '',
        'date':     '',
        'friends':  '',
        'solo':     '',
    }
    scene = args.scene.lower()
    scene_query_suffix = SCENE_QUERY_MAP.get(scene, '')
    scene_tone = SCENE_TONE.get(scene, '')

    # äººæ•°æ„ŸçŸ¥
    people = args.people
    if people >= 5:
        scene_query_suffix += ' å¤§æ¡Œ åŒ…é—´'

    # æ¨æ–­ locale
    locale = args.locale if args.locale != 'auto' else detect_locale(args.query, args.city, profile)
    print(f"ğŸ“ Locale: {locale}", file=sys.stderr)

    # æŒ‰ locale è·¯ç”±æœç´¢
    if locale == 'china':
        print(f"ğŸ‡¨ğŸ‡³ ä¸­å›½æ¨¡å¼ï¼šé«˜å¾·/ç™¾åº¦åœ°å›¾ â†’ å¤§ä¼—ç‚¹è¯„/å°çº¢ä¹¦è¡¥å……", file=sys.stderr)

        # ä» query é‡Œæå–åŒºåŸŸä¿¡æ¯
        district = ''
        district_keywords = ['å²³éº“åŒº', 'æœé˜³åŒº', 'æµ·æ·€åŒº', 'ä¸œåŸåŒº', 'è¥¿åŸåŒº', 'å¤©å¿ƒåŒº',
                             'èŠ™è“‰åŒº', 'é›¨èŠ±åŒº', 'å¼€ç¦åŒº', 'æœ›åŸåŒº']
        for dk in district_keywords:
            if dk in args.query or dk in args.city:
                district = dk
                clean_city = args.city or ''.join(
                    c for c in args.query if '\u4e00' <= c <= '\u9fff' or c.isalpha()
                ).replace(dk, '').strip()
                break

        # ä¸»æ•°æ®æºï¼šé«˜å¾·åœ°å›¾ï¼ˆæœ‰ AMAP_KEY å°±ç”¨ï¼Œæ²¡æœ‰æ‰é™çº§ï¼‰
        has_map_key = bool(os.environ.get('AMAP_KEY') or os.environ.get('BMAP_KEY'))
        if has_map_key:
            # ä» query æå–åŒºåŸŸå…³é”®è¯
            district = ''
            district_patterns = ['é…’ä»™æ¡¥', 'ä¸‰é‡Œå±¯', 'æœ›äº¬', 'å›½è´¸', 'æœé˜³', 'æµ·æ·€',
                                  'äº®é©¬æ²³', '798', 'å·¥ä½“', 'ä¸œç›´é—¨', 'è¥¿ç›´é—¨', 'äº”é“å£',
                                  'å²³éº“åŒº', 'æœé˜³åŒº', 'æµ·æ·€åŒº', 'ä¸œåŸåŒº', 'è¥¿åŸåŒº']
            for dp in district_patterns:
                if dp in args.query:
                    district = dp
                    break
            map_query = re.sub(r'(é…’ä»™æ¡¥|ä¸‰é‡Œå±¯|æœ›äº¬|å›½è´¸|äº®é©¬æ²³|798|å·¥ä½“)', '', args.query).strip()
            if scene_query_suffix:
                map_query = f"{map_query} {scene_query_suffix}".strip()
            merged = search_maps(map_query or args.query, args.city, district, mode='china', max_results=args.max)
            # ç¤¾äº¤åª’ä½“äº¤å‰éªŒè¯ï¼ˆtop 5ï¼‰
            merged = cross_verify_social(merged, max_verify=5)
        else:
            print(f"  âš ï¸  æœªé…ç½® AMAP_KEYï¼Œé™çº§åˆ°å¤§ä¼—ç‚¹è¯„æœç´¢", file=sys.stderr)
            dp_results = search_dianping(args.query, args.city, max_results=args.max)
            merged = dp_results

        for r in merged:
            r['match_score'] = match_score(r, preferences, locale)

    elif locale == 'overseas-chinese':
        print(f"ğŸŒ æµ·å¤–åäººæ¨¡å¼ï¼šGoogle Maps + å°çº¢ä¹¦", file=sys.stderr)
        merged = search_serper_maps(f"{args.query} restaurant", args.city, args.max)
        # å°çº¢ä¹¦è¡¥å……
        xhs = search_xiaohongshu(f"{args.query} {args.city} æ¢åº—", max_results=10)
        for note in xhs:
            for mentioned in note.get('restaurants_mentioned', []):
                for r in merged:
                    if mentioned in r['name'] or r['name'] in mentioned:
                        r['xhs_verified'] = True
                        r['sources'].append('xiaohongshu')
        for r in merged:
            r['match_score'] = match_score(r, preferences, locale)

    else:  # overseas
        print(f"ğŸŒ æµ·å¤–æ¨¡å¼ï¼šGoogle Maps + Reddit", file=sys.stderr)
        merged = search_serper_maps(f"{args.query} restaurant", args.city, args.max)
        for r in merged:
            r['match_score'] = match_score(r, preferences, locale)

    merged.sort(key=lambda x: (x.get('cross_verified', False), x.get('match_score', 50)), reverse=True)

    if args.json:
        print(json.dumps(merged, ensure_ascii=False, indent=2))
        return

    if not merged:
        print("æ²¡æœ‰æ‰¾åˆ°ç›¸å…³é¤å… / No restaurants found")
        return

    if args.mode == '2plus1':
        precise, explorer = select_2plus1(merged)
        _print_2plus1(precise, explorer, args.query, locale, preferences, scene_tone, people)
    else:
        _print_list(merged[:10], locale)


def _print_2plus1(precise, explorer, query, locale, preferences, scene_tone='', people=2):
    print(f"\nğŸ« å°é¥­ç¥¨ 2+1 æ¨èï¼š{query}")
    if scene_tone:
        print(f"   {scene_tone}\n")
    elif preferences.get('liked_tags'):
        print(f"   (å·²æ ¹æ®ä½ çš„å£å‘³ç”»åƒç­›é€‰)\n")

    print("â”â”â” ç²¾å‡†æ¨è â”â”â”\n")
    for i, r in enumerate(precise, 1):
        _print_one(i, r, locale, preferences=preferences)

    if explorer:
        print("\nâ”â”â” æ¢ç´¢æ¨è â”â”â”\n")
        _print_one(1, explorer[0], locale, is_explorer=True, preferences=preferences)

    if people >= 5:
        print("\nâš ï¸  5 ä¸ªäººä»¥ä¸Šå»ºè®®æå‰æ‰“ç”µè¯é¢„çº¦ï¼Œåˆ«ç™½è·‘ä¸€è¶Ÿã€‚")


def _print_list(results, locale):
    for i, r in enumerate(results, 1):
        _print_one(i, r, locale)


def _generate_personal_blurb(r: dict, preferences: dict) -> str:
    """æ ¹æ®å£å‘³ç”»åƒç”Ÿæˆä¸ªæ€§åŒ–æ¨èè¯­ï¼ˆæ™®é€šæ¨¡å¼ä¸“ç”¨ï¼‰"""
    liked_tags = set(preferences.get('liked_tags', []))
    disliked_tags = set(preferences.get('disliked_tags', []))
    price_range = preferences.get('price_range', [])

    name = r.get('name', '')
    type_label = r.get('type', '')
    cuisines = set(r.get('cuisines', []) + [type_label])
    address = r.get('address', '') or ''
    price = r.get('avg_price', 0) or 0
    score = r.get('score', 0) or 0

    parts = []

    # å£å‘³åŒ¹é… â€” è¯´"ä¸ºä»€ä¹ˆé€‚åˆä½ "
    taste_hints = {
        'äº‘å—èœ': 'ä½ å–œæ¬¢é¦™æ–™ï¼Œè¿™å®¶äº‘å—èœå¯¹ä½ è·¯å­',
        'æ½®æ±•': 'æ½®æ±•èœè®²ç©¶é£Ÿææœ¬å‘³ï¼Œä½ åº”è¯¥ä¼šå–œæ¬¢',
        'ç²¤èœ': 'ç²¤èœè®²ç©¶é£Ÿæï¼Œç¬¦åˆä½ çš„å£å‘³',
        'æ—¥æ–™': 'æ—¥æ–™ï¼Œä½ å–œæ¬¢çš„æ–¹å‘',
        'ç§æˆ¿èœ': 'ç§æˆ¿èœï¼Œä¸æ˜¯è¿é”ï¼Œæœ‰è‡ªå·±çš„é£æ ¼',
        'ç²¾è‡´å°é¦†': 'ç²¾è‡´å°é¦†ï¼Œä½ å–œæ¬¢çš„é‚£ç§',
        'Bistro': 'Bistro é£æ ¼ï¼Œä½ å–œæ¬¢çš„è°ƒæ€§',
        'æœ‰è°ƒæ€§': 'ç¯å¢ƒæœ‰è°ƒæ€§ï¼Œä½ åº”è¯¥ä¼šå–œæ¬¢',
    }
    for tag, hint in taste_hints.items():
        if tag in liked_tags and tag in cuisines:
            parts.append(hint)
            break

    # ä¸å–œæ¬¢çš„æ ‡ç­¾ â€” ä¸»åŠ¨è¯´"ä¸æ˜¯é‚£ç§"
    if 'è¿é”' in disliked_tags and any(kw in name for kw in ['è€åº—', 'åˆ›å§‹', 'æœ¬åº—']):
        parts.append('æœ¬åœ°è€åº—ï¼Œä¸æ˜¯è¿é”')

    # å°çº¢ä¹¦å£ç¢‘
    if r.get('xhs_verified'):
        if r.get('xhs_sentiment') == 'negative':
            parts.append('ç•™ä¸ªå¿ƒçœ¼ï¼Œæœ‰å·®è¯„')
        else:
            parts.append('å°çº¢ä¹¦æœ‰æ¢åº—ï¼Œæœ¬åœ°äººå»è¿‡')

    # ä»·æ ¼åŒ¹é…
    if price and price_range and len(price_range) == 2:
        low, high = price_range
        if low <= price <= high:
            parts.append(f'äººå‡ Â¥{price}ï¼Œåœ¨ä½ çš„é¢„ç®—é‡Œ')
        elif price > high * 1.3:
            parts.append(f'äººå‡ Â¥{price}ï¼Œç¨å¾®è´µä¸€ç‚¹ï¼Œä½†å€¼å¾—')

    # é«˜åˆ†èƒŒä¹¦ï¼ˆæ²¡æœ‰å…¶ä»–å†…å®¹æ—¶ï¼‰
    if not parts and score >= 4.7:
        parts.append(f'4.7 åˆ†ï¼Œå£ç¢‘åœ¨é‚£é‡Œ')

    return 'ã€‚'.join(parts[:2]) + 'ã€‚' if parts else ''


def _print_one(index, r, locale, is_explorer=False, preferences=None):
    name = r['name']
    prefix = "ğŸ " if is_explorer else ""

    if locale == 'china':
        price = f"Â¥{r['avg_price']}" if r.get('avg_price') else ''
        score = f"â­{r['score']}" if r.get('score') else ''
    else:
        price = '$' * r['price_level'] if r.get('price_level') else ''
        score = f"â­{r['score']}" if r.get('score') else ''

    info = ' | '.join(p for p in [price, score] if p)
    print(f"{prefix}{index}. {name}")
    if info:
        print(f"   {info}")

    # ä¸ªæ€§åŒ–æ¨èè¯­
    blurb = r.get('blurb', '')
    if not blurb and preferences:
        blurb = _generate_personal_blurb(r, preferences)
    if blurb:
        print(f"   {blurb}")

    if r.get('address'):
        print(f"   ğŸ“ {r['address'][:55]}")
    print()


if __name__ == '__main__':
    main()
