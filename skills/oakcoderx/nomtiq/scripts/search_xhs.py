#!/usr/bin/env python3
"""
å°é¥­å¡ - å°çº¢ä¹¦æ¢åº—æœç´¢ï¼ˆä½¿ç”¨ Serper APIï¼‰
ç”¨æ³•:
  python3 search_xhs.py "ä¸‰é‡Œå±¯ å®è—é¤å…"
  python3 search_xhs.py "å›½è´¸ æ—¥æ–™" --max 30 --json
"""

import sys
import json
import argparse
import re
import os
import subprocess

SERPER_API_KEY = os.environ.get('SERPER_API_KEY') or '380883ffc186cebf26d0681c1a65482f499f5fe7'


def search_xiaohongshu(query: str, max_results: int = 30) -> list:
    """æœç´¢å°çº¢ä¹¦æ¢åº—ç¬”è®°ï¼ˆä½¿ç”¨ search-hubï¼‰
    
    Args:
        query: æœç´¢å…³é”®è¯
        max_results: æœ€å¤§ç»“æœæ•°ï¼ˆé»˜è®¤ 30 æ¡ç¬”è®°ï¼‰
    """
    search_query = f'site:xiaohongshu.com {query} æ¢åº—'
    
    try:
        # è°ƒç”¨ search-hubï¼ˆç”¨ python3.13ï¼‰
        result = subprocess.run(
            ['python3.13', 'skills/search-hub/scripts/hub.py', 'search', search_query, '-t', 'text', '-l', str(max_results)],
            cwd='/Users/mac/.openclaw/workspace',
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode != 0:
            print(f"search-hub å‡ºé”™ï¼š{result.stderr}", file=sys.stderr)
            return []
        
        # è§£æ JSON è¾“å‡º
        data = json.loads(result.stdout)
        results = data.get('results', [])
        
        # è§£æç¬”è®°
        notes = []
        for r in results:
            parsed = parse_xhs_result(r)
            if parsed:
                notes.append(parsed)
        
        return notes
        
    except Exception as e:
        print(f"æœç´¢å‡ºé”™ï¼š{e}", file=sys.stderr)
        return []


def serper_search(query: str, max_results: int = 25) -> list:
    """ä½¿ç”¨ Serper API æœç´¢"""
    url = "https://google.serper.dev/search"
    
    payload = {
        "q": query,
        "num": max_results,
        "gl": "cn",
        "hl": "zh-cn"
    }
    
    headers = {
        'X-API-TOKEN': SERPER_API_KEY,
        'Content-Type': 'application/json'
    }
    
    response = requests.post(url, json=payload, headers=headers, timeout=30)
    response.raise_for_status()
    
    data = response.json()
    return data.get('organic', [])


def parse_xhs_result(result):
    """è§£æå°çº¢ä¹¦æœç´¢ç»“æœ"""
    title = result.get('title', '')
    snippet = result.get('snippet', '')
    url = result.get('link', '')
    combined = f"{title} {snippet}"

    # åˆ¤æ–­æ˜¯å¦é¤å…ç›¸å…³
    food_keywords = ['é¤å…', 'æ¢åº—', 'å¥½åƒ', 'ç¾é£Ÿ', 'èœ', 'é¦†', 'æ–™ç†', 'æ‰“å¡', 'å¿…åƒ', 'æ¨è', 'äººå‡']
    if not any(kw in combined for kw in food_keywords):
        return None

    # æå–æåˆ°çš„é¤å…åï¼ˆé€šå¸¸åœ¨æ ‡é¢˜æˆ–æ­£æ–‡ä¸­ä»¥ä¹¦åå·æ ‡æ³¨ï¼‰
    restaurant_names = re.findall(r'[ã€Œã€ã€ã€Š](.+?)[ã€ã€ã€‘ã€‹]', combined)
    if not restaurant_names:
        # å°è¯•ä»æ ‡é¢˜æå–
        name_match = re.search(r'^([^|!\n]+)', title)
        if name_match:
            restaurant_names = [name_match.group(1).strip()]

    # æå–äººå‡
    price_match = re.search(r'[äººå‡Â¥ï¿¥](\d+)', combined)
    avg_price = int(price_match.group(1)) if price_match else None

    # åˆ¤æ–­æƒ…æ„Ÿï¼ˆæ­£é¢/è´Ÿé¢ï¼‰
    positive_words = ['å¥½åƒ', 'æ¨è', 'ç»äº†', 'æƒŠè‰³', 'å®è—', 'ç¥ä»™', 'å¿…åƒ', 'å›è´­', 'è¶…èµ', 'æ»¡åˆ†', 'çˆ±äº†']
    negative_words = ['è¸©é›·', 'ä¸å¥½åƒ', 'æ‹”è‰', 'å¤±æœ›', 'éš¾åƒ', 'ä¸æ¨è', 'ä¸€èˆ¬', 'é¿é›·', 'ç¿»è½¦']
    
    pos_count = sum(1 for w in positive_words if w in combined)
    neg_count = sum(1 for w in negative_words if w in combined)

    if neg_count > pos_count:
        sentiment = 'negative'
    elif pos_count > neg_count:
        sentiment = 'positive'
    else:
        sentiment = 'neutral'

    return {
        'title': title,
        'snippet': snippet[:200],
        'url': url,
        'restaurants_mentioned': restaurant_names[:3],  # æœ€å¤šæå– 3 ä¸ªé¤å…å
        'avg_price': avg_price,
        'sentiment': sentiment,
    }


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='å°é¥­å¡ - å°çº¢ä¹¦æœç´¢')
    parser.add_argument('query', help='æœç´¢å…³é”®è¯')
    parser.add_argument('--max', type=int, default=30, help='æœ€å¤§ç»“æœæ•°')
    parser.add_argument('--json', action='store_true', help='JSON è¾“å‡º')
    args = parser.parse_args()

    results = search_xiaohongshu(args.query, max_results=args.max)

    if args.json:
        print(json.dumps(results, ensure_ascii=False, indent=2))
    else:
        print(f"ğŸ“• æ‰¾åˆ° {len(results)} æ¡ç¬”è®°\n")
        for i, note in enumerate(results[:10], 1):
            sentiment_emoji = {'positive': 'ğŸ‘', 'negative': 'âš ï¸', 'neutral': ''}
            s_emoji = sentiment_emoji.get(note.get('sentiment'), '')
            restaurants = ', '.join(note.get('restaurants_mentioned', [])[:2])
            print(f"{i}. {note['title'][:50]}")
            print(f"   {s_emoji} æåˆ°ï¼š{restaurants}")
            print()
