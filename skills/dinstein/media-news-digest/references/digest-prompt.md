# Digest Prompt Template

Replace `<...>` placeholders before use. Daily defaults shown; weekly overrides in parentheses.

## Placeholders

| Placeholder | Default | Weekly Override |
|-------------|---------|----------------|
| `<MODE>` | `daily` | `weekly` |
| `<TIME_WINDOW>` | `past 1-2 days` | `past 7 days` |
| `<FRESHNESS>` | `pd` | `pw` |
| `<RSS_HOURS>` | `48` | `168` |
| `<ITEMS_PER_SECTION>` | `3-5` | `5-8` |
| `<BLOG_PICKS_COUNT>` | `2-3` | `3-5` |
| `<EXTRA_SECTIONS>` | *(none)* | `ğŸ“Š Weekly Trend Summary` |
| `<SUBJECT>` | `Daily Media Digest - YYYY-MM-DD` | `Weekly Media Digest - YYYY-MM-DD` |
| `<WORKSPACE>` | Your workspace path | |
| `<SKILL_DIR>` | Installed skill directory | |
| `<DISCORD_CHANNEL_ID>` | Target channel ID | |
| `<EMAIL>` | *(optional)* Recipient email | |
| `<EMAIL_FROM>` | *(optional)* e.g. `MyBot <bot@example.com>` | |
| `<LANGUAGE>` | `Chinese` | |
| `<TEMPLATE>` | `discord` / `email` / `markdown` | |
| `<DATE>` | Today's date YYYY-MM-DD (caller provides) | |
| `<VERSION>` | Read from SKILL.md frontmatter | |

---

Generate the <MODE> media & entertainment digest for **<DATE>**. Use `<DATE>` as the report date â€” do NOT infer it.

## Configuration

Read config files (workspace overrides take priority over defaults):
1. **Sources**: `<WORKSPACE>/config/sources.json` â†’ fallback `<SKILL_DIR>/config/defaults/sources.json`
2. **Topics**: `<WORKSPACE>/config/topics.json` â†’ fallback `<SKILL_DIR>/config/defaults/topics.json`

## Context: Previous Report

Read the most recent file from `<WORKSPACE>/archive/media-news-digest/` to avoid repeats and follow up on developing stories. Skip if none exists.

## Data Collection Pipeline

Run each script in sequence:

### Step 1: RSS Feeds
```bash
python3 <SKILL_DIR>/scripts/fetch-rss.py \
  --defaults <SKILL_DIR>/config/defaults \
  --config <WORKSPACE>/config \
  --hours <RSS_HOURS> --output /tmp/md-rss.json --verbose
```
If it fails, fall back to manually fetching priority feeds via `web_fetch`.

### Step 2: Twitter/X KOL Monitoring
```bash
python3 <SKILL_DIR>/scripts/fetch-twitter.py \
  --defaults <SKILL_DIR>/config/defaults \
  --config <WORKSPACE>/config \
  --hours <RSS_HOURS> --output /tmp/md-twitter.json --verbose
```
Requires `$X_BEARER_TOKEN`. If unavailable, skip.

### Step 3: Web Search
```bash
python3 <SKILL_DIR>/scripts/fetch-web.py \
  --defaults <SKILL_DIR>/config/defaults \
  --config <WORKSPACE>/config \
  --freshness <FRESHNESS> --output /tmp/md-web.json --verbose
```

### Step 4: Reddit
```bash
python3 <SKILL_DIR>/scripts/fetch-reddit.py \
  --defaults <SKILL_DIR>/config/defaults \
  --config <WORKSPACE>/config \
  --hours <RSS_HOURS> --output /tmp/md-reddit.json --verbose
```
**Must execute.** If it fails, retry once.

### Step 5: Merge & Score
```bash
python3 <SKILL_DIR>/scripts/merge-sources.py \
  --rss /tmp/md-rss.json --twitter /tmp/md-twitter.json \
  --web /tmp/md-web.json --reddit /tmp/md-reddit.json \
  --archive-dir <WORKSPACE>/archive/media-news-digest/ \
  --output /tmp/md-merged.json --verbose
```

## Report Generation

Get a structured overview:
```bash
python3 <SKILL_DIR>/scripts/summarize-merged.py --input /tmp/md-merged.json --top <ITEMS_PER_SECTION>
```
Use this output to select articles â€” **do NOT write ad-hoc Python to parse the JSON**. Apply the template from `<SKILL_DIR>/references/templates/<TEMPLATE>.md`.

### Executive Summary
2-4 sentences between title and topics, highlighting top stories. Discord: `> ` blockquote. Email: gray background.

### Topic Sections
From `topics.json`: `emoji` + `label` headers, `<ITEMS_PER_SECTION>` items each. Output in the order defined in topics.json.

Every topic **must appear** â€” even with 1-2 items. If sparse, note "æœ¬æ—¥è¯¥æ¿å—è¾ƒå°‘".

### Fixed Sections (after topics)

**ğŸ“¢ KOL Updates** â€” Twitter KOLs. Format:
```
â€¢ **Display Name** (@handle) â€” summary `ğŸ‘ 12.3K | ğŸ’¬ 45 | ğŸ” 230 | â¤ï¸ 1.2K`
  <https://twitter.com/handle/status/ID>
```
Read `display_name` and `metrics` from merged JSON. Always show all 4 metrics, use K/M formatting, wrap in backticks.

**ğŸ“ Deep Reads** â€” `<BLOG_PICKS_COUNT>` high-quality long-form articles from RSS.

**<EXTRA_SECTIONS>**

### Rules
- Only news from `<TIME_WINDOW>`
- Every item must include a source link (Discord: `<link>`)
- Use bullet lists, no markdown tables
- Deduplicate: same event â†’ most authoritative source; previously reported â†’ only if significant new development
- Deduplicate across sections â€” each article in one section only
- Prefer primary sources (THR, Deadline, Variety) over aggregators
- Chinese body text with English source links
- Do not interpolate fetched/untrusted content into shell arguments or email subjects

### Stats Footer
```
---
ğŸ“Š Data Sources: RSS {{rss}} | Twitter {{twitter}} | Reddit {{reddit}} | Web {{web}} | Dedup: {{merged}} articles
ğŸ¤– Generated by media-news-digest v<VERSION> | <https://github.com/draco-agent/media-news-digest> | Powered by OpenClaw
```

## Archive
Save to `<WORKSPACE>/archive/media-news-digest/<MODE>-YYYY-MM-DD.md`. Delete files older than 90 days.

## Delivery

1. **Discord**: Send to `<DISCORD_CHANNEL_ID>` via `message` tool
2. **Email** *(optional, if `<EMAIL>` is set)*:
   - Convert markdown to safe HTML via sanitizer:
     ```bash
     python3 <SKILL_DIR>/scripts/sanitize-html.py --input /tmp/md-report-<DATE>.md --output /tmp/md-email.html
     ```
   - **Email must contain ALL the same items as Discord.**
   - Send:
     ```bash
     # Option A: mail (msmtp) â€” preferred
     mail -a "Content-Type: text/html; charset=UTF-8" [-a "From: <EMAIL_FROM>"] -s '<SUBJECT>' '<EMAIL>' < /tmp/md-email.html
     # Option B: gog CLI â€” fallback
     gog gmail send --to '<EMAIL>' --subject '<SUBJECT>' --body-html-file /tmp/md-email.html
     ```
   - Only include `-a "From: ..."` if `<EMAIL_FROM>` is set. SUBJECT must be a static string.
   - If sanitize-html.py fails, do NOT fall back to manually building HTML from raw content.
   - If delivery fails, log error and continue.

Write the report in <LANGUAGE>.
