---
name: humanize-chinese
description: Detect and humanize AI-generated Chinese text with 6 style transforms (casual/zhihu/xiaohongshu/wechat/academic/literary). Removes "AI flavor" using 16 detection patterns. Pure Python, no dependencies. v1.1.0
allowed-tools:
  - Read
  - Write
  - Edit
  - exec
---

# Humanize Chinese AI Text

Comprehensive CLI for detecting and transforming Chinese AI-generated text. Makes robotic AI writing natural and human-like with 6 specialized writing style transforms.

**NEW in v1.1:** Style transforms (çŸ¥ä¹Ž/å°çº¢ä¹¦/å…¬ä¼—å·/å£è¯­åŒ–/å­¦æœ¯/æ–‡è‰º), enhanced detection (16 patterns), emotional analysis

## Quick Start

```bash
# Detect AI patterns (16 categories)
python scripts/detect_cn.py text.txt

# Humanize text
python scripts/humanize_cn.py text.txt -o clean.txt

# Scene-specific humanization
python scripts/humanize_cn.py text.txt --scene social  # Social media
python scripts/humanize_cn.py text.txt --scene tech    # Tech blog
python scripts/humanize_cn.py text.txt --scene formal  # Formal article

# NEW: Apply writing styles
python scripts/humanize_cn.py text.txt --style zhihu -o zhihu.txt
python scripts/humanize_cn.py text.txt --style xiaohongshu -o xhs.txt
python scripts/style_cn.py text.txt --style casual -o casual.txt

# List all available styles
python scripts/style_cn.py --list

# Compare before/after
python scripts/compare_cn.py text.txt -o clean.txt
```

---

## Detection Categories

The analyzer checks for **16 pattern categories** specific to Chinese AI text (v1.1 added 4 new patterns):

### Critical (Immediate AI Detection)
| Category | Examples |
|----------|----------|
| Three-Part Structure | é¦–å…ˆ...å…¶æ¬¡...æœ€åŽ, ä¸€æ–¹é¢...å¦ä¸€æ–¹é¢ |
| Mechanical Connectors | å€¼å¾—æ³¨æ„çš„æ˜¯, ç»¼ä¸Šæ‰€è¿°, ä¸éš¾å‘çŽ° |
| Empty Grand Words | èµ‹èƒ½, é—­çŽ¯, æ™ºæ…§æ—¶ä»£, æ•°å­—åŒ–è½¬åž‹ |

### High Signal
| Category | Examples |
|----------|----------|
| AI High-Frequency Words | åŠ©åŠ›, å½°æ˜¾, å‡¸æ˜¾, ç„•å‘, æ·±åº¦å‰–æž |
| Technical Jargon Misuse | è§£æž„, é‡å­çº ç¼ , å…‰è°± (in non-tech context) |
| Excessive Rhetoric | å¯¹å¶å¥ (>2x), æŽ’æ¯”å¥ (>1x), å¼•ç”¨å¥ (>4x) |

### Medium Signal
| Category | Examples |
|----------|----------|
| Punctuation Overuse | Dense em dashes, excessive semicolons |
| Obscure Metaphors | Forced, disconnected comparisons |
| Uniform Paragraphs | Equal-length paragraphs (no rhythm) |

### Style Signal
| Category | Examples |
|----------|----------|
| Low Burstiness | Monotonous sentence structure |
| Low Perplexity | Predictable word choices |
| Emotional Flatness | **NEW** Lack of emotional words and expressions |
| Repetitive Structure | **NEW** Sentence starters repeat >3 times |
| Slang Overuse | **NEW** Internet slang in formal context |
| Vocabulary Homogeneity | **NEW** Low diversity in word choice |

---

## Writing Style Transforms (NEW in v1.1)

Transform text into 6 specialized Chinese writing styles:

| Style | Name | Description | Best For |
|-------|------|-------------|----------|
| `casual` | å£è¯­åŒ–é£Žæ ¼ | Like chatting with friends â€” natural, relaxed | Social media, messaging |
| `zhihu` | çŸ¥ä¹Žé£Žæ ¼ | Rational, in-depth, with personal opinions | Q&A platforms, thoughtful analysis |
| `xiaohongshu` | å°çº¢ä¹¦é£Žæ ¼ | Enthusiastic, emoji-rich, product-focused | Lifestyle sharing, reviews, recommendations |
| `wechat` | å…¬ä¼—å·é£Žæ ¼ | Storytelling, engaging, relatable | WeChat articles, newsletters |
| `academic` | å­¦æœ¯é£Žæ ¼ | Rigorous but not stiff, precise terminology | Academic papers, research reports |
| `literary` | æ–‡è‰ºé£Žæ ¼ | Poetic, imagery-rich, metaphorical | Creative writing, essays |

### Usage

```bash
# Apply style directly
python scripts/style_cn.py input.txt --style zhihu -o output.txt

# Combine humanization + style
python scripts/humanize_cn.py ai_text.txt --style xiaohongshu -o natural.txt

# List all styles
python scripts/style_cn.py --list
```

### Style Features

#### Casual (å£è¯­åŒ–)
- Removes formal structure (é¦–å…ˆ/å…¶æ¬¡/æœ€åŽ)
- Adds colloquial connectors (è¯´å®žè¯, ç¡®å®ž, å…¶å®ž)
- Includes tone particles (å§, å‘¢, å•Š)
- Light emoji usage

#### Zhihu (çŸ¥ä¹Ž)
- Personal opinion markers (ä»Žæˆ‘çš„ç»éªŒæ¥çœ‹, ä¸ªäººè®¤ä¸º)
- Data/evidence support (å®žæµ‹å‘çŽ°, æ ¹æ®XXè°ƒç ”)
- Example-driven (ä¸¾ä¸ªä¾‹å­)
- Logical but conversational

#### Xiaohongshu (å°çº¢ä¹¦)
- Enthusiastic openers (å§å¦¹ä»¬ï¼åˆ†äº«ä¸€ä¸‹ï½ž)
- High emoji density (ðŸ˜Šâœ¨ðŸ’¯)
- Intensifiers (è¶…çº§, å·¨, ç»ç»å­, yyds)
- Hashtags (#å¥½ç‰©åˆ†äº«)
- Short paragraphs

#### Wechat (å…¬ä¼—å·)
- Story-driven openings
- Questions for engagement (ä½ æœ‰æ²¡æœ‰æƒ³è¿‡)
- Relatable scenarios
- Emotional connection

#### Academic (å­¦æœ¯)
- Removes colloquialisms
- Precise terminology
- Formal connectors (ç ”ç©¶è¡¨æ˜Ž, æ•°æ®æ˜¾ç¤º)
- Reduces emotional expressions

#### Literary (æ–‡è‰º)
- Metaphors and imagery
- Poetic language
- Descriptive phrases (åœ¨XXçš„å…‰å½±é‡Œ)
- Artistic expressions

---

## Scripts

### detect_cn.py â€” Scan Chinese AI Patterns

```bash
python scripts/detect_cn.py essay.txt
python scripts/detect_cn.py essay.txt -j  # JSON output
python scripts/detect_cn.py essay.txt -s  # score only
echo "æ–‡æœ¬" | python scripts/detect_cn.py
```

**Output:**
- AI feature statistics (by category)
- AI probability score (low/medium/high/very high)
- Auto-fixable patterns marked
- Perplexity and burstiness indicators

### humanize_cn.py â€” Transform to Human-Like

```bash
python scripts/humanize_cn.py essay.txt
python scripts/humanize_cn.py essay.txt -o output.txt
python scripts/humanize_cn.py essay.txt --scene social  # Social media style
python scripts/humanize_cn.py essay.txt -a              # Aggressive mode
```

**Scene Parameters (--scene):**
- `social`: Social media (casual, conversational)
- `tech`: Tech blog (professional but approachable)
- `formal`: Formal article (rigorous but natural)
- `chat`: Chat/dialogue (friendly, concise)

**Auto-fixes:**
- Remove three-part structure (é¦–å…ˆ/å…¶æ¬¡/æœ€åŽ)
- Replace mechanical connectors (å€¼å¾—æ³¨æ„çš„æ˜¯ â†’ æ³¨æ„/è¦æé†’çš„æ˜¯)
- Simplify empty words (èµ‹èƒ½ â†’ å¸®åŠ©/æå‡, é—­çŽ¯ â†’ å®Œæ•´æµç¨‹)
- Reduce punctuation density (em dash, semicolon)
- Control rhetoric frequency (å¯¹å¶, æŽ’æ¯”, æ¯”å–»)

**Aggressive Mode (-a):**
- Add colloquial expressions
- Inject emotional color
- Vary sentence rhythm
- Add personal perspective

### compare_cn.py â€” Before/After Analysis

```bash
python scripts/compare_cn.py essay.txt
python scripts/compare_cn.py essay.txt --scene tech -o clean.txt
```

Shows AI feature comparison and score changes before/after transformation.

### style_cn.py â€” Writing Style Transform (NEW)

```bash
python scripts/style_cn.py essay.txt --style zhihu -o essay_zhihu.txt
python scripts/style_cn.py blog.txt --style xiaohongshu -o blog_xhs.txt
python scripts/style_cn.py --list  # Show all available styles
```

**Supported styles:** casual, zhihu, xiaohongshu, wechat, academic, literary

Transform text into specific Chinese writing styles with style-appropriate vocabulary, tone, and structure.

---

## Workflow

1. **Scan** for detection risk:
   ```bash
   python scripts/detect_cn.py document.txt
   ```

2. **Transform** with comparison:
   ```bash
   python scripts/compare_cn.py document.txt --scene tech -o document_v2.txt
   ```

3. **Verify** improvement:
   ```bash
   python scripts/detect_cn.py document_v2.txt -s
   ```

4. **Manual review** for content quality and scene appropriateness

---

## AI Probability Scoring

| Rating | Criteria |
|--------|----------|
| Very High | Three-part structure, mechanical connectors, or empty grand words present |
| High | >20 issues OR issue density >3% |
| Medium | >10 issues OR issue density >1.5% |
| Low | <10 issues AND density <1.5% |

---

## Scene-Specific Guidelines

### Social Media (ç¤¾äº¤åª’ä½“)
**Style:** Casual, conversational, like chatting with friends
- âœ… Short paragraphs (1-3 sentences)
- âœ… Colloquial expressions (è¯´å®žè¯, æ²¡æƒ³åˆ°, çœŸçš„ç»äº†)
- âœ… Specific details (product names, locations, personal feelings)
- âœ… Emoji and hashtags
- âŒ Avoid: å€¼å¾—æ³¨æ„çš„æ˜¯, æ€»è€Œè¨€ä¹‹
- âŒ Avoid: Long paragraphs, complex sentences

### Tech Blog (æŠ€æœ¯åšå®¢)
**Style:** Professional but approachable, can be humorous
- âœ… Specific tech stack, tool names
- âœ… Code examples, performance data
- âœ… Real experiences ("è¸©è¿‡çš„å‘", "å®žæµ‹æ•ˆæžœ")
- âœ… Clear structure with headings (not numbered lists)
- âŒ Avoid: èµ‹èƒ½, é—­çŽ¯, ç”Ÿæ€
- âŒ Avoid: é¦–å…ˆ/å…¶æ¬¡/æœ€åŽstructure

### Formal Article (æ­£å¼æ–‡ç« )
**Style:** Objective, rigorous, but natural
- âœ… Clear logic with proper evidence
- âœ… Precise academic expressions
- âœ… Cited research sources
- âœ… Data and charts supporting arguments
- âŒ Avoid: Excessive rhetoric (å¯¹å¶, æŽ’æ¯”)
- âŒ Avoid: Empty grand words

### Chat/Dialogue (å¯¹è¯åœºæ™¯)
**Style:** Friendly, patient, genuine
- âœ… Concise, targeted responses
- âœ… Empathy and understanding
- âœ… Direct solutions
- âœ… Moderate emoji use
- âŒ Avoid: å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ (template phrases)
- âŒ Avoid: Lengthy explanations, repetitive questions

---

## Customizing Patterns

Edit `scripts/patterns_cn.json` to add/modify:
- `ai_vocabulary_cn` â€” Chinese AI high-frequency words
- `filler_phrases_cn` â€” ClichÃ©s and replacements
- `empty_words_cn` â€” Empty grand vocabulary
- `rhetoric_limits` â€” Rhetoric frequency limits
- `scene_styles` â€” Scene-specific style configs

---

## Batch Processing

```bash
# Scan all files
for f in *.txt; do
  echo "=== $f ==="
  python scripts/detect_cn.py "$f" -s
done

# Transform all markdown (tech blog style)
for f in *.md; do
  python scripts/humanize_cn.py "$f" --scene tech -o "${f%.md}_clean.md"
done
```

---

## Reference

Based on comprehensive Chinese AI writing research:
- Tencent News: "Deconstructing 'AI Flavor': Why We Dislike AI Writing"
- 53AI: "Detection and Optimization of Article 'AI Flavor'"
- AIGCleaner and other Chinese de-AI tools
- Wikipedia: "Signs of AI Writing" (English reference)

Key insights:
- **Perplexity**: AI text has low perplexity (predictable word choices)
- **Burstiness**: AI text has low burstiness (uniform sentence structure)
- **Emotion**: AI text lacks strong opinions and personal color
